{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "<font color='green'>\n",
    "\n",
    "# Project Solution: Neural Network - Part 3\n",
    "### Filename: Signal.csv\n",
    "### File consists of data with information on various signal tests performed:\n",
    "- 1. Parameters: Various measurable signal parameters.\n",
    "- 2. Signal_Quality: Final signal strength or quality\n",
    "\n",
    "### Context: A communications equipment manufacturing company has a product which is responsible for emitting informative  signals. Company wants to build a machine learning model which can help the company to predict the equipmentâ€™s signal quality using various parameters.\n",
    "\n",
    "### Purpose: Implementing a clickable GUI which can automate Part 1 (NN Regressor) and Part 2 (NN Classifier)\n",
    "\n",
    "***\n",
    "***\n",
    "*Prepared by: Sauvik De*\n",
    "\n",
    "*Date: March 5, 2021*\n",
    "    \n",
    "</font>\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Import Library\n",
    "import tkinter as tk\n",
    "from tkinter import ttk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from pathlib import Path\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization, ReLU, LeakyReLU #Flatten, Input\n",
    "from tensorflow.keras.optimizers import Adam, SGD, Adadelta, RMSprop\n",
    "from tensorflow.keras.initializers import he_uniform, he_normal, glorot_uniform, glorot_normal, RandomNormal\n",
    "\n",
    "def r_2_score(y_true, y_pred):\n",
    "    SS_resid = K.sum(K.square( y_true - y_pred )) \n",
    "    SS_total = K.sum(K.square( y_true - K.mean(y_true) ))\n",
    "    return ( 1 - SS_resid/(SS_total + 0.0000001) )  # 0.0000001 to avoid division by 0\n",
    "\n",
    "# App window\n",
    "win = tk.Tk()\n",
    "win.title('Neural Networks GUI - Great Learning')  # Window Title\n",
    "\n",
    "\n",
    "# Step 1: Import data frame name ---------------------------------\n",
    "\n",
    "Name = ttk.Label(win, text=\"Step 1: File Name\")\n",
    "Name.grid(row=0, column=0, sticky=tk.W)\n",
    "\n",
    "Name_var = tk.StringVar()\n",
    "Name_entrybox = ttk.Entry(win, width=16, textvariable=Name_var)\n",
    "Name_entrybox.grid(row=0, column=1)\n",
    "\n",
    "def Import_Data():\n",
    "    global DB\n",
    "    DF_Name = Name_var.get()\n",
    "    if((DF_Name != \"\") and (Path(DF_Name).exists())):\n",
    "        DB_extension = re.findall(\"\\..*\", DF_Name) \n",
    "        if DB_extension == ['.xlsx']:\n",
    "            DB = pd.read_excel(DF_Name)\n",
    "        elif DB_extension == ['.csv']:\n",
    "            DB = pd.read_csv(DF_Name)\n",
    "        # Blank empty window to print confirmation\n",
    "        confirm = \"Done\"\n",
    "    \n",
    "    else:\n",
    "        confirm = \"File unavailable\"\n",
    "    \n",
    "    Confirm_entrybox = ttk.Entry(win, width=16)\n",
    "    Confirm_entrybox.grid(row=0, column=3)\n",
    "    Confirm_entrybox.insert(1, str(confirm))\n",
    "    Confirm_entrybox.config(state='readonly')\n",
    "\n",
    "Import_Data_Button = ttk.Button(win, text=\"Import Data\", command=Import_Data)\n",
    "Import_Data_Button.grid(row=0, column=2)\n",
    "\n",
    "\n",
    "# Step 2: Target column name ---------------------------------\n",
    "\n",
    "Target = ttk.Label(win, text=\"Step 2: Target Column\")\n",
    "Target.grid(row=1, column=0, sticky=tk.W)\n",
    "\n",
    "Target_var = tk.StringVar()\n",
    "Target_entrybox = ttk.Entry(win, width=16, textvariable=Target_var)\n",
    "Target_entrybox.grid(row=1, column=1)\n",
    "\n",
    "def Target_Data():\n",
    "    global DB, X, y, Target_Name, X_train, X_test, y_train, y_test\n",
    "    Target_Name = Target_var.get()\n",
    "    \n",
    "    if('DB' in globals()):\n",
    "        if(Target_Name != \"\"):\n",
    "            Column_name = DB.columns\n",
    "\n",
    "            for i in range(len(Column_name)):\n",
    "                if Column_name[i]==Target_Name:\n",
    "                    confirm=\"Found\"\n",
    "                    y = DB[Target_Name]                                # Target variable\n",
    "                    X = DB.drop(Target_Name, axis=1, inplace=False)    # Predictor variable\n",
    "                    # Train and test split\n",
    "                    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=1, shuffle=True)\n",
    "\n",
    "                else:\n",
    "                    confirm=\"Not Found\"\n",
    "        else:\n",
    "            confirm=\"No input target\"\n",
    "    else:\n",
    "        confirm=\"No Input File\"\n",
    "                \n",
    "    Confirm_entrybox = ttk.Entry(win, width=16)\n",
    "    Confirm_entrybox.grid(row=1, column=3)\n",
    "    Confirm_entrybox.insert(1, str(confirm))\n",
    "    Confirm_entrybox.config(state='readonly')\n",
    "\n",
    "Target_Button = ttk.Button(win, text=\"Import Target\", command=Target_Data)\n",
    "Target_Button.grid(row=1, column=2)\n",
    "\n",
    "\n",
    "# Step 3: Modelling ---------------------------------\n",
    "\n",
    "# ================================================\n",
    "# 1. Regression\n",
    "ModellingR = ttk.Label(win, text=\"Step 3: Neural Network Regressor\")\n",
    "ModellingR.grid(row=2, column=0, sticky=tk.W)\n",
    "\n",
    "NNR = ttk.Label(win, text=\"Regression\")\n",
    "NNR.grid(row=3, column=0, sticky=tk.E)\n",
    "\n",
    "def NN_Regression_Train():\n",
    "    global regmdl\n",
    "    if(('X_train' in globals()) & ('X_test' in globals()) & ('y_train' in globals()) & ('y_test' in globals())):\n",
    "        # Data Pre-processing ...\n",
    "        # Normalize data\n",
    "        sc = StandardScaler()\n",
    "        X_train_sc = sc.fit_transform(X_train)\n",
    "        X_test_sc  = sc.transform(X_test)\n",
    "        # Auto-detect number of principal components ...\n",
    "        cov_matrix = np.cov(X_train_sc.T)\n",
    "        # Compute Eigen values and Eigen vectors of the covariance matrix\n",
    "        eig_vals, eig_vecs = np.linalg.eig(cov_matrix)\n",
    "        # calculate cumulative proportion of variances of eigen vectors\n",
    "        var_exp = [ (i/sum(eig_vals)) * 100 for i in sorted(eig_vals, reverse=True)]\n",
    "        cum_var_exp = np.cumsum(var_exp)\n",
    "        PCcomp = (np.round(cum_var_exp,0) <= 95).sum()\n",
    "        # using Principal components ...\n",
    "        \n",
    "        pca = PCA(n_components=PCcomp)\n",
    "        X_train_proj = pca.fit_transform(X_train_sc)\n",
    "        X_test_proj  = pca.transform(X_test_sc)\n",
    "        \n",
    "        # Step 1: Design Neural Network regressor\n",
    "        # Initialize model\n",
    "        regmdl = Sequential()\n",
    "        # Input Layer\n",
    "        regmdl.add(tf.keras.Input(shape=(X_train_proj.shape[1])))\n",
    "        # Add Hidden Layers with Leaky ReLU activation; Dropout for regularization (to prevent overefitting)\n",
    "        regmdl.add(Dense(256, activation=LeakyReLU(), kernel_initializer=glorot_uniform(seed=1), name='HL1'))\n",
    "        regmdl.add(Dropout(0.10))\n",
    "        regmdl.add(Dense(256, activation=LeakyReLU(), kernel_initializer=glorot_uniform(seed=1), name='HL2'))\n",
    "        regmdl.add(Dropout(0.10))\n",
    "        regmdl.add(Dense(128, activation=LeakyReLU(), kernel_initializer=glorot_uniform(seed=1), name='HL3'))\n",
    "        regmdl.add(Dropout(0.10))\n",
    "        regmdl.add(Dense(128, activation=LeakyReLU(), kernel_initializer=glorot_uniform(seed=1), name='HL4'))\n",
    "        regmdl.add(Dropout(0.10))\n",
    "        regmdl.add(Dense(64, activation=LeakyReLU(), kernel_initializer=glorot_uniform(seed=1), name='HL5'))\n",
    "        regmdl.add(Dropout(0.10))\n",
    "        regmdl.add(Dense(64, activation=LeakyReLU(), kernel_initializer=glorot_uniform(seed=1), name='HL6'))\n",
    "        regmdl.add(Dropout(0.10))\n",
    "        regmdl.add(Dense(32, activation=LeakyReLU(), kernel_initializer=glorot_uniform(seed=1), name='HL7'))\n",
    "        regmdl.add(Dropout(0.10))\n",
    "        regmdl.add(Dense(32, activation=LeakyReLU(), kernel_initializer=glorot_uniform(seed=1), name='HL8'))\n",
    "        regmdl.add(Dropout(0.10))\n",
    "        regmdl.add(Dense(16, activation=LeakyReLU(), kernel_initializer=glorot_uniform(seed=1), name='HL9'))\n",
    "        regmdl.add(Dropout(0.10))\n",
    "        regmdl.add(Dense(16, activation=LeakyReLU(), kernel_initializer=glorot_uniform(seed=1), name='HL10'))\n",
    "        regmdl.add(Dropout(0.10))\n",
    "        # Output Layer with 1 neuron and linear activation function\n",
    "        regmdl.add(Dense(1, activation='linear', kernel_initializer=glorot_uniform(seed=1), name='Output'))\n",
    "        \n",
    "        # Step 2: Compile model\n",
    "        regmdl.compile(optimizer=Adam(learning_rate=0.009), loss='mean_squared_error', metrics=[r_2_score])\n",
    "\n",
    "        # Step 3: Model Fitting\n",
    "        callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True, mode='min')\n",
    "        hist = regmdl.fit(X_train_proj, y_train, batch_size=64, epochs=1000, verbose=0,\n",
    "                          validation_data=(X_test_proj, y_test), callbacks=[callback])\n",
    "        \n",
    "        confirm = 'Network Trained'\n",
    "    \n",
    "    else:\n",
    "        confirm = 'Model input unavailable'\n",
    "\n",
    "    Confirm_entrybox = ttk.Entry(win, width=21)\n",
    "    Confirm_entrybox.grid(row=3, column=2)\n",
    "    Confirm_entrybox.insert(1, str(confirm))\n",
    "    Confirm_entrybox.config(state='readonly')\n",
    "    \n",
    "Reg_Train_Button = ttk.Button(win, text=\"Train\", command=NN_Regression_Train)\n",
    "Reg_Train_Button.grid(row=3, column=1)\n",
    "\n",
    "# -------------------------------------\n",
    "NNRP = ttk.Label(win, text=\"Pickle\")\n",
    "NNRP.grid(row=4, column=0, sticky=tk.E)\n",
    "\n",
    "def NN_Regression_Pickle():\n",
    "    if 'regmdl' in globals():\n",
    "        # serialize model to JSON\n",
    "        JSONmodel = regmdl.to_json()\n",
    "        #save the model architecture to JSON file\n",
    "        with open('nn_regression_model.json', 'w') as JSONfile:\n",
    "            JSONfile.write(JSONmodel)\n",
    "        #saving the weights of the model\n",
    "        regmdl.save_weights('nn_regression_weights.h5')\n",
    "        \n",
    "        confirm = 'Saved Model to disk'\n",
    "        \n",
    "    else:\n",
    "        confirm = 'No model available'\n",
    "    \n",
    "    Confirm_entrybox = ttk.Entry(win, width=18)\n",
    "    Confirm_entrybox.grid(row=4, column=2)\n",
    "    Confirm_entrybox.insert(1, str(confirm))\n",
    "    Confirm_entrybox.config(state='readonly')\n",
    "\n",
    "Reg_Pkl_Button = ttk.Button(win, text=\"Run\", command=NN_Regression_Pickle)\n",
    "Reg_Pkl_Button.grid(row=4, column=1)\n",
    "\n",
    "# ================================================\n",
    "# 2. Classification\n",
    "\n",
    "ModellingC = ttk.Label(win, text=\"Step 4: Neural Network Classifier\")\n",
    "ModellingC.grid(row=5, column=0, sticky=tk.W)\n",
    "\n",
    "NNC = ttk.Label(win, text=\"Classifier\")\n",
    "NNC.grid(row=6, column=0, sticky=tk.E)\n",
    "\n",
    "def NN_Classification_Train():\n",
    "    global clfmdl\n",
    "    if(('X_train' in globals()) & ('X_test' in globals()) & ('y_train' in globals()) & ('y_test' in globals())):\n",
    "        # Data Pre-processing ...\n",
    "        # Normalize data\n",
    "        sc = StandardScaler()\n",
    "        X_train_sc = sc.fit_transform(X_train)\n",
    "        X_test_sc  = sc.transform(X_test)\n",
    "        # Auto-detect number of principal components ...\n",
    "        cov_matrix = np.cov(X_train_sc.T)\n",
    "        # Compute Eigen values and Eigen vectors of the covariance matrix\n",
    "        eig_vals, eig_vecs = np.linalg.eig(cov_matrix)\n",
    "        # calculate cumulative proportion of variances of eigen vectors\n",
    "        var_exp = [ (i/sum(eig_vals)) * 100 for i in sorted(eig_vals, reverse=True)]\n",
    "        cum_var_exp = np.cumsum(var_exp)\n",
    "        PCcomp = (np.round(cum_var_exp,0) <= 95).sum()\n",
    "        # using Principal components ...\n",
    "        pca = PCA(n_components=PCcomp)\n",
    "        X_train_proj = pca.fit_transform(X_train_sc)\n",
    "        X_test_proj  = pca.transform(X_test_sc)\n",
    "        # to apply One-Hot-Encoding, we first shift class labels to start from 0\n",
    "        y_train_sh = y_train - y_train.min()\n",
    "        y_test_sh  = y_test  - y_test.min()\n",
    "        # One-Hot-Encode target column for signal strength \n",
    "        y_train_enc = tf.keras.utils.to_categorical(y_train_sh, num_classes=y_train.nunique())\n",
    "        y_test_enc  = tf.keras.utils.to_categorical(y_test_sh, num_classes=y_test.nunique())\n",
    "        \n",
    "        # Step 1: Design Neural Network classifier\n",
    "        # Initialize model\n",
    "        clfmdl = Sequential()\n",
    "        # Input Layer\n",
    "        clfmdl.add(tf.keras.Input(shape=(X_train_proj.shape[1])))\n",
    "        # Add Hidden Layers with Leaky ReLU activation; Dropout for regularization (to prevent overefitting)\n",
    "        clfmdl.add(Dense(256, activation=LeakyReLU(), kernel_initializer=glorot_uniform(seed=1), name='HL1'))\n",
    "        clfmdl.add(Dropout(0.10))\n",
    "        clfmdl.add(Dense(256, activation=LeakyReLU(), kernel_initializer=glorot_uniform(seed=1), name='HL2'))\n",
    "        clfmdl.add(Dropout(0.10))\n",
    "        clfmdl.add(Dense(128, activation=LeakyReLU(), kernel_initializer=glorot_uniform(seed=1), name='HL3'))\n",
    "        clfmdl.add(Dropout(0.10))\n",
    "        clfmdl.add(Dense(128, activation=LeakyReLU(), kernel_initializer=glorot_uniform(seed=1), name='HL4'))\n",
    "        clfmdl.add(Dropout(0.10))\n",
    "        clfmdl.add(Dense(64, activation=LeakyReLU(), kernel_initializer=glorot_uniform(seed=1), name='HL5'))\n",
    "        clfmdl.add(Dropout(0.10))\n",
    "        clfmdl.add(Dense(64, activation=LeakyReLU(), kernel_initializer=glorot_uniform(seed=1), name='HL6'))\n",
    "        clfmdl.add(Dropout(0.10))\n",
    "        clfmdl.add(Dense(32, activation=LeakyReLU(), kernel_initializer=glorot_uniform(seed=1), name='HL7'))\n",
    "        clfmdl.add(Dropout(0.10))\n",
    "        clfmdl.add(Dense(32, activation=LeakyReLU(), kernel_initializer=glorot_uniform(seed=1), name='HL8'))\n",
    "        clfmdl.add(Dropout(0.10))\n",
    "        clfmdl.add(Dense(16, activation=LeakyReLU(), kernel_initializer=glorot_uniform(seed=1), name='HL9'))\n",
    "        clfmdl.add(Dropout(0.10))\n",
    "        clfmdl.add(Dense(16, activation=LeakyReLU(), kernel_initializer=glorot_uniform(seed=1), name='HL10'))\n",
    "        clfmdl.add(Dropout(0.10))\n",
    "        # Output Layer with 6 neurons (equal to number of target classes) and softmax activation function\n",
    "        clfmdl.add(Dense(y_train.nunique(), activation='softmax', kernel_initializer=glorot_uniform(seed=1), name='Output'))\n",
    "        \n",
    "        # Step 2: Compile model\n",
    "        clfmdl.compile(optimizer=Adam(learning_rate=0.01), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "        # Step 3: Model Fitting\n",
    "        callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True, mode='min')\n",
    "        hist = clfmdl.fit(X_train_proj, y_train_enc, batch_size=64, epochs=1000, verbose=0,\n",
    "                          validation_data=(X_test_proj, y_test_enc), callbacks=[callback])\n",
    "        \n",
    "        confirm = 'Network Trained'\n",
    "    \n",
    "    else:\n",
    "        confirm = 'Model input unavailable'\n",
    "\n",
    "    Confirm_entrybox = ttk.Entry(win, width=21)\n",
    "    Confirm_entrybox.grid(row=6, column=2)\n",
    "    Confirm_entrybox.insert(1, str(confirm))\n",
    "    Confirm_entrybox.config(state='readonly')\n",
    "\n",
    "Clf_Train_Button = ttk.Button(win, text=\"Train\", command=NN_Classification_Train)\n",
    "Clf_Train_Button.grid(row=6, column=1)\n",
    "\n",
    "# -------------------------------------\n",
    "NNCP = ttk.Label(win, text=\"Pickle\")\n",
    "NNCP.grid(row=7, column=0, sticky=tk.E)\n",
    "\n",
    "def NN_Classification_Pickle():\n",
    "    if 'clfmdl' in globals():\n",
    "        # serialize model to JSON\n",
    "        JSONmodel = clfmdl.to_json()\n",
    "        #save the model architecture to JSON file\n",
    "        with open('nn_classification_model.json', 'w') as JSONfile:\n",
    "            JSONfile.write(JSONmodel)\n",
    "        #saving the weights of the model\n",
    "        clfmdl.save_weights('nn_classification_weights.h5')\n",
    "        \n",
    "        confirm = 'Saved Model to disk'\n",
    "        \n",
    "    else:\n",
    "        confirm = 'No model available'\n",
    "    \n",
    "    Confirm_entrybox = ttk.Entry(win, width=18)\n",
    "    Confirm_entrybox.grid(row=7, column=2)\n",
    "    Confirm_entrybox.insert(1, str(confirm))\n",
    "    Confirm_entrybox.config(state='readonly')\n",
    "\n",
    "Clf_Pkl_Button = ttk.Button(win, text=\"Run\", command=NN_Classification_Pickle)\n",
    "Clf_Pkl_Button.grid(row=7, column=1)\n",
    "\n",
    "win.mainloop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
